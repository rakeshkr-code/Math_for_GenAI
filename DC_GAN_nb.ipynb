{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p8kjVKoDthhv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "# import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import torchvision\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAXnM5ybXS5M",
        "outputId": "f1b0b963-b605-407e-9258-f7ee41960ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Devide : cuda\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "z_dim = 100\n",
        "image_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "beta1 = 0.5 # Adam optimizer beta1\n",
        "# beta2 = 0.999\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Devide : {device}\")\n",
        "\n",
        "# Create output folder\n",
        "# if not os.path.exists(\"generated_imgs\"):\n",
        "os.makedirs(\"generated_imgs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNsOrVYewFgj",
        "outputId": "37a388fe-91c0-4f69-f3b8-43ad004f86c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 477kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.37MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.73MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Transform: Normalize images between [-1, 1] (because Tanh will be used as output)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))    # Normalize between [-1, 1]\n",
        "])\n",
        "\n",
        "# Load MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ceda4a32"
      },
      "outputs": [],
      "source": [
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xcAAtxsgzZ0g"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: (N, z_dim, 1, 1)\n",
        "            nn.ConvTranspose2d(z_dim, 256, kernel_size=7, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.net(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rN6u3tlq6Y23"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: (N, 1, 28, 28)\n",
        "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 7 * 7, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, img):\n",
        "        return self.net(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kxCRtq_HCxeT"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "generator = Generator(z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Loss - Binary Cross Entropy Loss\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fUwFbxPs9o79"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(epoch):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(64, z_dim, 1, 1).to(device)\n",
        "        fake_images = generator(z)\n",
        "        fake_images = fake_images * 0.5 + 0.5  # Denormalize to [0,1]\n",
        "        save_image(fake_images, f\"generated_imgs/sample_epoch_{epoch}.png\", nrow=8)\n",
        "    generator.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FCtxK7Bui44H"
      },
      "outputs": [],
      "source": [
        "k = 3   # Generator updates per iteration\n",
        "p = 1   # Discriminator updates per iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s-RNKRTkAMd",
        "outputId": "7b20af9a-f81c-4c08-f237-282b45e99a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step or Batch [0/469], D_loss: 1.3600 | G_loss: 0.5878\n",
            "Epoch [1/50], Step or Batch [200/469], D_loss: 1.2518 | G_loss: 0.7615\n",
            "Epoch [1/50], Step or Batch [400/469], D_loss: 1.2640 | G_loss: 0.9243\n",
            "Epoch [2/50], Step or Batch [0/469], D_loss: 1.2030 | G_loss: 1.0682\n",
            "Epoch [2/50], Step or Batch [200/469], D_loss: 1.1677 | G_loss: 0.8792\n",
            "Epoch [2/50], Step or Batch [400/469], D_loss: 1.2151 | G_loss: 0.8165\n",
            "Epoch [3/50], Step or Batch [0/469], D_loss: 1.1769 | G_loss: 0.7157\n",
            "Epoch [3/50], Step or Batch [200/469], D_loss: 1.1885 | G_loss: 0.9161\n",
            "Epoch [3/50], Step or Batch [400/469], D_loss: 1.1251 | G_loss: 0.8118\n",
            "Epoch [4/50], Step or Batch [0/469], D_loss: 1.1756 | G_loss: 0.7406\n",
            "Epoch [4/50], Step or Batch [200/469], D_loss: 1.2145 | G_loss: 0.7074\n",
            "Epoch [4/50], Step or Batch [400/469], D_loss: 1.0967 | G_loss: 0.9615\n",
            "Epoch [5/50], Step or Batch [0/469], D_loss: 1.1558 | G_loss: 0.8886\n",
            "Epoch [5/50], Step or Batch [200/469], D_loss: 1.1462 | G_loss: 0.5883\n",
            "Epoch [5/50], Step or Batch [400/469], D_loss: 1.1580 | G_loss: 0.9272\n",
            "Epoch [6/50], Step or Batch [0/469], D_loss: 1.1294 | G_loss: 0.8577\n",
            "Epoch [6/50], Step or Batch [200/469], D_loss: 1.2174 | G_loss: 1.2408\n",
            "Epoch [6/50], Step or Batch [400/469], D_loss: 1.2820 | G_loss: 0.5088\n",
            "Epoch [7/50], Step or Batch [0/469], D_loss: 1.2428 | G_loss: 0.6585\n",
            "Epoch [7/50], Step or Batch [200/469], D_loss: 1.0628 | G_loss: 1.0715\n",
            "Epoch [7/50], Step or Batch [400/469], D_loss: 1.1527 | G_loss: 0.8518\n",
            "Epoch [8/50], Step or Batch [0/469], D_loss: 1.1677 | G_loss: 0.6704\n",
            "Epoch [8/50], Step or Batch [200/469], D_loss: 1.0853 | G_loss: 0.9535\n",
            "Epoch [8/50], Step or Batch [400/469], D_loss: 1.1817 | G_loss: 0.9899\n",
            "Epoch [9/50], Step or Batch [0/469], D_loss: 1.0664 | G_loss: 1.2098\n",
            "Epoch [9/50], Step or Batch [200/469], D_loss: 1.1437 | G_loss: 1.0380\n",
            "Epoch [9/50], Step or Batch [400/469], D_loss: 1.2160 | G_loss: 0.7513\n",
            "Epoch [10/50], Step or Batch [0/469], D_loss: 1.0769 | G_loss: 1.1825\n",
            "Epoch [10/50], Step or Batch [200/469], D_loss: 1.3607 | G_loss: 1.7221\n",
            "Epoch [10/50], Step or Batch [400/469], D_loss: 1.1512 | G_loss: 0.8000\n",
            "Epoch [11/50], Step or Batch [0/469], D_loss: 1.1010 | G_loss: 1.0271\n",
            "Epoch [11/50], Step or Batch [200/469], D_loss: 1.2213 | G_loss: 0.8011\n",
            "Epoch [11/50], Step or Batch [400/469], D_loss: 1.1261 | G_loss: 0.8947\n",
            "Epoch [12/50], Step or Batch [0/469], D_loss: 1.2461 | G_loss: 0.5111\n",
            "Epoch [12/50], Step or Batch [200/469], D_loss: 1.0829 | G_loss: 1.0503\n",
            "Epoch [12/50], Step or Batch [400/469], D_loss: 1.1079 | G_loss: 0.9581\n",
            "Epoch [13/50], Step or Batch [0/469], D_loss: 1.0926 | G_loss: 1.2780\n",
            "Epoch [13/50], Step or Batch [200/469], D_loss: 1.2636 | G_loss: 0.5549\n",
            "Epoch [13/50], Step or Batch [400/469], D_loss: 1.1422 | G_loss: 1.0402\n",
            "Epoch [14/50], Step or Batch [0/469], D_loss: 1.2321 | G_loss: 1.3875\n",
            "Epoch [14/50], Step or Batch [200/469], D_loss: 1.1379 | G_loss: 0.9694\n",
            "Epoch [14/50], Step or Batch [400/469], D_loss: 1.1746 | G_loss: 0.8327\n",
            "Epoch [15/50], Step or Batch [0/469], D_loss: 1.1480 | G_loss: 0.6324\n",
            "Epoch [15/50], Step or Batch [200/469], D_loss: 1.2060 | G_loss: 1.5848\n",
            "Epoch [15/50], Step or Batch [400/469], D_loss: 1.1821 | G_loss: 1.0270\n",
            "Epoch [16/50], Step or Batch [0/469], D_loss: 1.1857 | G_loss: 0.6428\n",
            "Epoch [16/50], Step or Batch [200/469], D_loss: 1.2399 | G_loss: 0.8033\n",
            "Epoch [16/50], Step or Batch [400/469], D_loss: 1.2784 | G_loss: 0.6888\n",
            "Epoch [17/50], Step or Batch [0/469], D_loss: 1.1263 | G_loss: 1.0407\n",
            "Epoch [17/50], Step or Batch [200/469], D_loss: 1.1407 | G_loss: 0.9154\n",
            "Epoch [17/50], Step or Batch [400/469], D_loss: 1.2211 | G_loss: 0.7259\n",
            "Epoch [18/50], Step or Batch [0/469], D_loss: 1.1305 | G_loss: 0.7513\n",
            "Epoch [18/50], Step or Batch [200/469], D_loss: 1.1525 | G_loss: 1.0570\n",
            "Epoch [18/50], Step or Batch [400/469], D_loss: 1.1312 | G_loss: 0.9441\n",
            "Epoch [19/50], Step or Batch [0/469], D_loss: 1.2562 | G_loss: 1.1491\n",
            "Epoch [19/50], Step or Batch [200/469], D_loss: 1.0977 | G_loss: 1.0993\n",
            "Epoch [19/50], Step or Batch [400/469], D_loss: 1.2806 | G_loss: 0.5231\n",
            "Epoch [20/50], Step or Batch [0/469], D_loss: 1.1248 | G_loss: 0.8912\n",
            "Epoch [20/50], Step or Batch [200/469], D_loss: 1.1171 | G_loss: 1.2753\n",
            "Epoch [20/50], Step or Batch [400/469], D_loss: 1.1762 | G_loss: 0.6216\n",
            "Epoch [21/50], Step or Batch [0/469], D_loss: 1.1161 | G_loss: 0.6514\n",
            "Epoch [21/50], Step or Batch [200/469], D_loss: 1.4021 | G_loss: 1.3015\n",
            "Epoch [21/50], Step or Batch [400/469], D_loss: 1.1033 | G_loss: 0.9060\n",
            "Epoch [22/50], Step or Batch [0/469], D_loss: 1.1150 | G_loss: 0.9767\n",
            "Epoch [22/50], Step or Batch [200/469], D_loss: 1.0401 | G_loss: 1.0170\n",
            "Epoch [22/50], Step or Batch [400/469], D_loss: 1.0231 | G_loss: 1.1670\n",
            "Epoch [23/50], Step or Batch [0/469], D_loss: 1.1123 | G_loss: 1.1031\n",
            "Epoch [23/50], Step or Batch [200/469], D_loss: 1.3366 | G_loss: 0.3709\n",
            "Epoch [23/50], Step or Batch [400/469], D_loss: 1.1143 | G_loss: 1.0134\n",
            "Epoch [24/50], Step or Batch [0/469], D_loss: 1.1027 | G_loss: 0.9252\n",
            "Epoch [24/50], Step or Batch [200/469], D_loss: 1.3735 | G_loss: 0.6619\n",
            "Epoch [24/50], Step or Batch [400/469], D_loss: 1.1218 | G_loss: 1.2240\n",
            "Epoch [25/50], Step or Batch [0/469], D_loss: 1.0945 | G_loss: 1.0477\n",
            "Epoch [25/50], Step or Batch [200/469], D_loss: 1.1556 | G_loss: 0.9276\n",
            "Epoch [25/50], Step or Batch [400/469], D_loss: 1.2551 | G_loss: 1.2472\n",
            "Epoch [26/50], Step or Batch [0/469], D_loss: 1.1591 | G_loss: 0.8408\n",
            "Epoch [26/50], Step or Batch [200/469], D_loss: 1.1288 | G_loss: 0.9848\n",
            "Epoch [26/50], Step or Batch [400/469], D_loss: 1.2383 | G_loss: 0.9702\n",
            "Epoch [27/50], Step or Batch [0/469], D_loss: 1.2905 | G_loss: 1.3707\n",
            "Epoch [27/50], Step or Batch [200/469], D_loss: 1.1717 | G_loss: 0.6982\n",
            "Epoch [27/50], Step or Batch [400/469], D_loss: 1.1526 | G_loss: 0.7551\n",
            "Epoch [28/50], Step or Batch [0/469], D_loss: 0.9996 | G_loss: 1.0723\n",
            "Epoch [28/50], Step or Batch [200/469], D_loss: 1.1606 | G_loss: 1.1412\n",
            "Epoch [28/50], Step or Batch [400/469], D_loss: 1.0588 | G_loss: 0.9896\n",
            "Epoch [29/50], Step or Batch [0/469], D_loss: 1.2260 | G_loss: 0.8733\n",
            "Epoch [29/50], Step or Batch [200/469], D_loss: 1.4142 | G_loss: 1.4902\n",
            "Epoch [29/50], Step or Batch [400/469], D_loss: 1.1976 | G_loss: 1.1957\n",
            "Epoch [30/50], Step or Batch [0/469], D_loss: 1.0524 | G_loss: 1.3916\n",
            "Epoch [30/50], Step or Batch [200/469], D_loss: 1.1585 | G_loss: 0.7937\n",
            "Epoch [30/50], Step or Batch [400/469], D_loss: 1.1303 | G_loss: 1.0097\n",
            "Epoch [31/50], Step or Batch [0/469], D_loss: 1.1784 | G_loss: 1.0429\n",
            "Epoch [31/50], Step or Batch [200/469], D_loss: 1.1526 | G_loss: 1.7864\n",
            "Epoch [31/50], Step or Batch [400/469], D_loss: 1.1904 | G_loss: 1.0680\n",
            "Epoch [32/50], Step or Batch [0/469], D_loss: 1.1622 | G_loss: 0.9132\n",
            "Epoch [32/50], Step or Batch [200/469], D_loss: 1.2019 | G_loss: 1.2068\n",
            "Epoch [32/50], Step or Batch [400/469], D_loss: 1.2308 | G_loss: 1.2538\n",
            "Epoch [33/50], Step or Batch [0/469], D_loss: 1.2770 | G_loss: 0.5615\n",
            "Epoch [33/50], Step or Batch [200/469], D_loss: 1.1496 | G_loss: 1.1669\n",
            "Epoch [33/50], Step or Batch [400/469], D_loss: 1.4121 | G_loss: 1.4212\n",
            "Epoch [34/50], Step or Batch [0/469], D_loss: 1.1632 | G_loss: 0.9505\n",
            "Epoch [34/50], Step or Batch [200/469], D_loss: 1.2050 | G_loss: 0.7319\n",
            "Epoch [34/50], Step or Batch [400/469], D_loss: 1.1656 | G_loss: 1.2367\n",
            "Epoch [35/50], Step or Batch [0/469], D_loss: 1.2641 | G_loss: 0.7966\n",
            "Epoch [35/50], Step or Batch [200/469], D_loss: 1.0624 | G_loss: 0.9302\n",
            "Epoch [35/50], Step or Batch [400/469], D_loss: 1.1467 | G_loss: 0.9530\n",
            "Epoch [36/50], Step or Batch [0/469], D_loss: 0.9862 | G_loss: 1.1960\n",
            "Epoch [36/50], Step or Batch [200/469], D_loss: 1.2117 | G_loss: 1.4075\n",
            "Epoch [36/50], Step or Batch [400/469], D_loss: 1.0561 | G_loss: 1.0705\n",
            "Epoch [37/50], Step or Batch [0/469], D_loss: 1.1245 | G_loss: 0.5823\n",
            "Epoch [37/50], Step or Batch [200/469], D_loss: 1.0460 | G_loss: 0.8233\n",
            "Epoch [37/50], Step or Batch [400/469], D_loss: 1.1842 | G_loss: 1.2339\n",
            "Epoch [38/50], Step or Batch [0/469], D_loss: 1.1397 | G_loss: 0.6300\n",
            "Epoch [38/50], Step or Batch [200/469], D_loss: 1.1328 | G_loss: 1.0529\n",
            "Epoch [38/50], Step or Batch [400/469], D_loss: 1.1370 | G_loss: 0.8197\n",
            "Epoch [39/50], Step or Batch [0/469], D_loss: 1.1918 | G_loss: 0.8291\n",
            "Epoch [39/50], Step or Batch [200/469], D_loss: 1.0703 | G_loss: 0.8861\n",
            "Epoch [39/50], Step or Batch [400/469], D_loss: 1.0983 | G_loss: 1.0879\n",
            "Epoch [40/50], Step or Batch [0/469], D_loss: 1.1280 | G_loss: 1.0689\n",
            "Epoch [40/50], Step or Batch [200/469], D_loss: 1.1823 | G_loss: 0.6261\n",
            "Epoch [40/50], Step or Batch [400/469], D_loss: 1.1698 | G_loss: 0.9605\n",
            "Epoch [41/50], Step or Batch [0/469], D_loss: 1.0766 | G_loss: 1.1217\n",
            "Epoch [41/50], Step or Batch [200/469], D_loss: 1.1498 | G_loss: 0.7853\n",
            "Epoch [41/50], Step or Batch [400/469], D_loss: 1.1501 | G_loss: 0.5808\n",
            "Epoch [42/50], Step or Batch [0/469], D_loss: 1.0828 | G_loss: 1.2466\n",
            "Epoch [42/50], Step or Batch [200/469], D_loss: 1.1724 | G_loss: 0.9440\n",
            "Epoch [42/50], Step or Batch [400/469], D_loss: 1.1421 | G_loss: 0.8177\n",
            "Epoch [43/50], Step or Batch [0/469], D_loss: 1.1503 | G_loss: 1.0475\n",
            "Epoch [43/50], Step or Batch [200/469], D_loss: 1.1948 | G_loss: 0.7250\n",
            "Epoch [43/50], Step or Batch [400/469], D_loss: 1.2936 | G_loss: 1.3650\n",
            "Epoch [44/50], Step or Batch [0/469], D_loss: 1.0845 | G_loss: 1.3001\n",
            "Epoch [44/50], Step or Batch [200/469], D_loss: 1.0146 | G_loss: 0.8277\n",
            "Epoch [44/50], Step or Batch [400/469], D_loss: 1.1151 | G_loss: 0.7236\n",
            "Epoch [45/50], Step or Batch [0/469], D_loss: 1.1167 | G_loss: 1.5503\n",
            "Epoch [45/50], Step or Batch [200/469], D_loss: 1.0829 | G_loss: 0.8021\n",
            "Epoch [45/50], Step or Batch [400/469], D_loss: 1.2407 | G_loss: 0.4822\n",
            "Epoch [46/50], Step or Batch [0/469], D_loss: 1.1195 | G_loss: 1.3470\n",
            "Epoch [46/50], Step or Batch [200/469], D_loss: 1.0933 | G_loss: 1.1196\n",
            "Epoch [46/50], Step or Batch [400/469], D_loss: 1.1184 | G_loss: 0.8679\n",
            "Epoch [47/50], Step or Batch [0/469], D_loss: 1.1447 | G_loss: 1.0137\n",
            "Epoch [47/50], Step or Batch [200/469], D_loss: 1.2280 | G_loss: 0.4546\n",
            "Epoch [47/50], Step or Batch [400/469], D_loss: 1.1237 | G_loss: 0.5959\n",
            "Epoch [48/50], Step or Batch [0/469], D_loss: 1.1747 | G_loss: 1.0172\n",
            "Epoch [48/50], Step or Batch [200/469], D_loss: 1.2659 | G_loss: 0.6336\n",
            "Epoch [48/50], Step or Batch [400/469], D_loss: 1.1776 | G_loss: 0.8585\n",
            "Epoch [49/50], Step or Batch [0/469], D_loss: 1.1599 | G_loss: 0.7710\n",
            "Epoch [49/50], Step or Batch [200/469], D_loss: 1.3121 | G_loss: 1.4425\n",
            "Epoch [49/50], Step or Batch [400/469], D_loss: 1.1025 | G_loss: 0.9969\n",
            "Epoch [50/50], Step or Batch [0/469], D_loss: 1.2397 | G_loss: 0.3826\n",
            "Epoch [50/50], Step or Batch [200/469], D_loss: 1.4422 | G_loss: 1.6610\n",
            "Epoch [50/50], Step or Batch [400/469], D_loss: 1.2467 | G_loss: 0.5127\n"
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "batch_size_curr = batch_size\n",
        "for epoch in range(1, epochs+1):\n",
        "    for i, (real_imgs, _) in enumerate(train_loader):\n",
        "        batch_size = real_imgs.size(0)\n",
        "        real_imgs = real_imgs.to(device)\n",
        "\n",
        "        # Use the actual batch size for creating target tensors\n",
        "        real = torch.ones(batch_size, 1, device=device)\n",
        "        fake = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "        ### ----- Train Discriminator p times ----- ###\n",
        "        for underscore in range(p):\n",
        "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            # Real\n",
        "            real_validity = discriminator(real_imgs)\n",
        "            d_real_loss = criterion(real_validity, real)\n",
        "\n",
        "            # Fake\n",
        "            fake_validity = discriminator(fake_imgs.detach())\n",
        "            d_fake_loss = criterion(fake_validity, fake)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "        ### ----- Train Generator k times ----- ###\n",
        "        for _ in range(k):\n",
        "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            validity = discriminator(fake_imgs)\n",
        "            g_loss = criterion(validity, real)  # fool D -> label as real\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "        if i % 200 == 0:\n",
        "            print(f\"Epoch [{epoch}/{epochs}], Step or Batch [{i}/{len(train_loader)}], \"\n",
        "                    f\"D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f}\")\n",
        "    # Save sample images\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(64, z_dim, 1, 1).to(device)\n",
        "        samples = generator(z)\n",
        "        samples = samples * 0.5 + 0.5  # Denormalize to [0,1]\n",
        "        save_image(samples, f\"generated_imgs/epoch_{epoch}.png\", nrow=8)\n",
        "    generator.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOf5RII5phI0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
